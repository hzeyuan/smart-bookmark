#!/usr/bin/env python3
"""
æµ‹è¯•é€šç”¨æµè§ˆå™¨ä»£ç†åŠŸèƒ½
éªŒè¯é‡æ„åçš„ BaseBrowserLabelsAgent æ˜¯å¦èƒ½ä½œä¸ºé€šç”¨æµè§ˆå™¨ä»£ç†å·¥ä½œ
"""
import asyncio
import logging
import json
from load_env import load_dotenv
load_dotenv()

from core import AutomationEngine

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


async def test_universal_browser_agent():
    """æµ‹è¯•é€šç”¨æµè§ˆå™¨ä»£ç†åœ¨ä¸åŒç½‘ç«™ä¸Šçš„è¡¨ç°"""
    
    test_cases = [
        {
            "name": "Googleæœç´¢æµ‹è¯•",
            "instruction": "æœç´¢'äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿'",
            "url": "https://www.google.com"
        },
        {
            "name": "çŸ¥ä¹æµ‹è¯•",
            "instruction": "æµè§ˆçŸ¥ä¹é¦–é¡µå†…å®¹",
            "url": "https://www.zhihu.com"
        },
        {
            "name": "GitHubæµ‹è¯•",
            "instruction": "æµè§ˆGitHubé¦–é¡µ",
            "url": "https://github.com"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ§ª æµ‹è¯• {i}/{len(test_cases)}: {test_case['name']}")
        logger.info(f"ğŸ“‹ ä»»åŠ¡: {test_case['instruction']}")
        logger.info(f"ğŸŒ ç½‘ç«™: {test_case['url']}")
        logger.info(f"{'='*60}")
        
        task_id = f"universal_test_{i}"
        
        try:
            async with AutomationEngine(task_id, headless=False) as engine:
                result = await engine.execute_task(test_case['instruction'], test_case['url'])
                
                # åˆ†æç»“æœ
                logger.info(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
                logger.info(f"   æˆåŠŸ: {'âœ…' if result.success else 'âŒ'}")
                logger.info(f"   æ­¥éª¤æ•°: {result.total_steps}")
                logger.info(f"   æ•°æ®æ¡æ•°: {len(result.final_data)}")
                
                if result.success and result.final_data:
                    logger.info(f"\nğŸ“¦ æå–çš„æ•°æ®ç±»å‹:")
                    for j, data in enumerate(result.final_data[:3], 1):
                        if isinstance(data, dict):
                            logger.info(f"   æ•°æ® {j}:")
                            if 'page_info' in data:
                                page_info = data['page_info']
                                logger.info(f"     é¡µé¢æ ‡é¢˜: {page_info.get('title', 'N/A')[:50]}...")
                                logger.info(f"     é¡µé¢URL: {page_info.get('url', 'N/A')}")
                            
                            if 'elements' in data:
                                elements = data['elements']
                                logger.info(f"     å¯äº¤äº’å…ƒç´ æ•°é‡: {len(elements)}")
                                
                                # åˆ†æå…ƒç´ ç±»å‹
                                element_types = {}
                                for elem in elements[:20]:  # åªåˆ†æå‰20ä¸ªå…ƒç´ 
                                    elem_type = elem.get('type', 'unknown')
                                    element_types[elem_type] = element_types.get(elem_type, 0) + 1
                                
                                logger.info(f"     å…ƒç´ ç±»å‹åˆ†å¸ƒ: {dict(sorted(element_types.items(), key=lambda x: x[1], reverse=True))}")
                            
                            if 'text_content' in data:
                                text_content = data['text_content']
                                logger.info(f"     æ–‡æœ¬å†…å®¹é•¿åº¦: {len(text_content)} å­—ç¬¦")
                                if text_content:
                                    logger.info(f"     æ–‡æœ¬ç‰‡æ®µ: {text_content[:100]}...")
                else:
                    logger.error(f"   é”™è¯¯: {result.error_message}")
                
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        # ç­‰å¾…ä¸€ä¸‹å†è¿›è¡Œä¸‹ä¸€ä¸ªæµ‹è¯•
        await asyncio.sleep(2)
    
    logger.info(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")


async def test_element_extraction():
    """ä¸“é—¨æµ‹è¯•å…ƒç´ æå–åŠŸèƒ½"""
    logger.info(f"\nğŸ”§ ä¸“é¡¹æµ‹è¯•: å…ƒç´ æå–åŠŸèƒ½")
    
    task_id = "element_extraction_test"
    url = "https://www.baidu.com"  # ä½¿ç”¨ç™¾åº¦æµ‹è¯•ï¼Œå› ä¸ºé¡µé¢ç»“æ„ç›¸å¯¹ç®€å•
    
    try:
        async with AutomationEngine(task_id, headless=False) as engine:
            # åˆå§‹åŒ–å¹¶å¯¼èˆªåˆ°é¡µé¢
            await engine.browser_agent.navigate_to(url)
            await engine.browser_agent.sleep(2000)
            
            # æµ‹è¯•è·å–å¯äº¤äº’å…ƒç´ 
            logger.info("ğŸ“‹ æµ‹è¯• get_clickable_elements...")
            clickable_data = await engine.browser_agent.get_clickable_elements(with_highlight=False)
            logger.info(f"   æ‰¾åˆ° {clickable_data.get('count', 0)} ä¸ªå¯äº¤äº’å…ƒç´ ")
            
            # æ˜¾ç¤ºå‰5ä¸ªå…ƒç´ çš„è¯¦ç»†ä¿¡æ¯
            if 'elements' in clickable_data:
                elements = clickable_data['elements']
                logger.info(f"\nğŸ“ å‰5ä¸ªå…ƒç´ è¯¦æƒ…:")
                for i, elem in enumerate(elements[:5], 1):
                    logger.info(f"   å…ƒç´  {i}:")
                    logger.info(f"     ç´¢å¼•: {elem.get('index')}")
                    logger.info(f"     æ ‡ç­¾: {elem.get('tag')}")
                    logger.info(f"     ç±»å‹: {elem.get('type')}")
                    logger.info(f"     æ–‡æœ¬: '{elem.get('text', '')[:30]}...'")
                    if elem.get('placeholder'):
                        logger.info(f"     å ä½ç¬¦: {elem.get('placeholder')}")
                    if elem.get('href'):
                        logger.info(f"     é“¾æ¥: {elem.get('href')[:50]}...")
            
            # æµ‹è¯•é¡µé¢å†…å®¹æå–
            logger.info(f"\nğŸ“„ æµ‹è¯• extract_page_content...")
            page_content = await engine.browser_agent.extract_page_content()
            logger.info(f"   é¡µé¢æ ‡é¢˜: {page_content.get('title', 'N/A')}")
            logger.info(f"   é¡µé¢URL: {page_content.get('page_url', 'N/A')}")
            logger.info(f"   å†…å®¹é•¿åº¦: {len(page_content.get('page_content', ''))} å­—ç¬¦")
            
            # æµ‹è¯•é€šç”¨æ•°æ®æå–
            logger.info(f"\nğŸ“Š æµ‹è¯• extract_page_data...")
            page_data = await engine.browser_agent.extract_page_data()
            logger.info(f"   æå–çš„æ•°æ®é¡¹æ•°: {len(page_data)}")
            
            if page_data:
                data = page_data[0]
                logger.info(f"   æ•°æ®ç»“æ„åŒ…å«: {list(data.keys())}")
            
    except Exception as e:
        logger.error(f"âŒ å…ƒç´ æå–æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    async def main():
        # é¦–å…ˆè¿è¡Œä¸“é¡¹æµ‹è¯•
        await test_element_extraction()
        
        # ç„¶åè¿è¡Œé€šç”¨æµ‹è¯•
        await test_universal_browser_agent()
    
    asyncio.run(main())